# Логирование
_ _ _
**Задачи** **журналирования:**
- Фиксация событий системы и сервисов (syslog)
- Аудит — событий безопасности, инциденты (auth.log)
- Исходные данные для мониторинга после агрегации (access.log)
- Отладка проблем и поиск сбоев (error.log)
- Восстановление действий до указанного момента (binlog)
- Аналитика и поведение пользователей (access.log)
- Сценарий для нагрузочного тестированиā (access.log)

  ## Типы логов
Типы логов
1. Текстовые
- Прямой записи: /var/log/nginx/access.log
- Через rsyslogd: /var/log/syslog или /var/log/messages
2. Бинарные (через systemd-journald): /var/log/journal/
3. База данных (Elasticsearch, MySQL)

  ### Текстовые логи 
- __/var/log/syslog или /var/log/messages содержит глобальный системный журнал, в котором пишутся сообщения с момента запуска системы, от ядра Linux, различных служб, обнаруженных устройствах, сетевых интерфейсов и много другого.__
- /var/log/auth.log или /var/log/secure — информация об авторизации пользователей, включая удачные и неудачные попытки входа в систему, а также задействованные механизмы аутентификации.
- /var/log/dmesg — драйвера устройств. Одноименной командой можно просмотреть вывод содержимого файла. Размер журнала ограничен, когда файл достигнет своего предела, старые сообщения будут перезаписаны более новыми. Задав ключ --level= можно отфильтровать вывод по критерию значимости    
- /var/log/alternatives.log — Вывод программы update-alternatives, в котором находятся символические ссылки на команды или библиотеки по умолчанию.
- /var/log/anaconda.log — Записи, зарегистрированные во время установки системы.
- /var/log/audit — Записи, созданные службой аудита auditd.
- /var/log/boot.log — Информация, которая пишется при загрузке операционной системы.
- /var/log/cron — Отчет службы crond об исполняемых командах и сообщения от самих команд.
- /var/log/cups — Все, что связано с печатью и принтерами

__Для каждого дистрибутива будет отдельный журнал менеджера пакетов.__     
- /var/log/yum.log — Для программ установленных с помощью Yum в RedHat Linux.
- /var/log/emerge.log — Для ebuild-ов установленных из Portage с помощью emerge в Gentoo Linux.
- /var/log/dpkg.log — Для программ установленных с помощью dpkg в Debian Linux и всем семействе родственных дистрибутивах.

__Бинарные журналы учета пользовательских сессий.__
- /var/log/lastlog — Последняя сессия пользователей. Прочитать можно командой last.
- /var/log/tallylog — Аудит неудачных попыток входа в систему. Вывод на экран с помощью утилиты pam_tally2.
- /var/log/btmp — Еже один журнал записи неудачных попыток входа в систему. Просто так, на всякий случай, если вы еще не догадались где следует искать следы активности взломщиков.
- /var/log/wtmp — Еще один журнал записи входа пользователей в систему. Вывод на экран командой utmpdump.     


__Поддерживаемые уровни журналирования (приоритеты):__
- emerg - система неиспользуемая
- alert - действие должно быть произведено немедленно
- crit - условия критичности
- err - условия ошибок
- warn - условия предупреждений
- notice - обычные, но значимые условия
- info - информационный
- debug - отладочные сообщения

```
cat syslog | grep err  - фильтрация логов
```
```
tail -n 10 syslog  - показать последние 10 строк
```
```
tail -f syslog - смотреть лог в реальном времени
```
```
head -n 10 syslog - показать первые 10 строк лога
```
#### rsyslog

rsyslog — это системный журнал (syslog-сервер) и клиент, который собирает, фильтрует, сохраняет и/или передаёт логи (журналы событий) в Linux-системах. Он является улучшенной и более производительной версией классического syslog. 
   
__Как работает rsyslog__
1. Программа (например sshd, cron, kernel) пишет сообщение в системный журнал.
2. Это сообщение попадает в rsyslogd (демон rsyslog).
3. rsyslog анализирует сообщение и:
- сохраняет его в файл,
- передаёт на другой сервер,
- или игнорирует — в зависимости от конфигурации.

__/etc/rsyslog.conf__ - конфигурационный файл в котором можно настроить сбор логов   
__/etc/rsyslog.d/*.conf__ - Дополнительные конфиги (в Ubuntu)    

__Пример конфигурации__
```
# Логировать все сообщения mail-сервиса уровня warning и выше в отдельный файл
mail.warning    /var/log/mail.warn

# Отправлять все сообщения уровня error и выше на удалённый syslog-сервер
*.err    @@192.168.1.10:514
```

##### Модули rsyslog
rsyslog  строится по модульной архитектуре, и именно за счёт модулей он стал таким мощным инструментом логирования.    

Модули — это плагины, которые расширяют функциональность rsyslog. Их можно загружать в конфигурации и использовать для:
- приёма сообщений (input)
- отправки сообщений (output)
- обработки сообщений (parser, filter)
- форматов, протоколов, баз данных и т.д.     

Каждый модуль `rsyslog` начинается с префикса, который определяет его назначение:

| Префикс | Назначение                 | Примеры             |
|---------|----------------------------|---------------------|
| `im`    | **Input module** — модуль ввода, принимает логи | `imudp`, `imtcp`, `imjournal` |
| `om`    | **Output module** — модуль вывода, отправляет логи | `omfile`, `omfwd`, `omelasticsearch` |
| `mm`    | **Message Modifier** — модуль изменения сообщений | `mmnormalize` |
| `pm`    | **Parser module** — модуль разбора сообщений     | `pmjsonparse`, `pmrfc5424` |
| `fm`    | **Function module** — вспомогательные функции     | специфичные модули |


### LOGROTATE
Logrotate - подсистема для автоматической ротации логов, с возможностью сжатия,удаления, перемещения и гибкой настройкой под каждый вид лог файлов     


Как правило, инструмент Logrotate установлен по умолчанию и базово настроен для обработки ротации логов всех установленных пакетов, включая rsyslog, обработчик системных логов по умолчанию     


__/etc/logrotate.d__  в системе сущетсвует ротация логов, старые логи сохраняются и сжимаются, в этом файле находятся файлы с настройками для каждого сервиса.   

__Ротация логов:__
- Хранение истории
- Сжатие старых логов
- Конфигурация /etc/logrotate.conf, /etc/logrotate.d/*
- Часто настройки ротации создаётся при установке пакета
- Скрипт запуска: /etc/cron.daily/logrotat




__Конфигурация Logrotate__
В Ubuntu информацию о конфигурации Logrotate обычно можно найти в двух местах:
- /etc/logrotate.conf: этот файл содержит стандартные параметры и настраивает ротацию для нескольких логов, которые не принадлежат никаким системным пакетам. Он также использует оператор include для извлечения конфигурации из любого файла в каталоге /etc/logrotate.d.
- /etc/logrotate.d/: этот каталог содержит конфигурацию Logrotate для всех устанавливаемых вами пакетов, которым требуется помощь в ротации логов. В стандартной установке там уже должны быть файлы для основных системных
инструментов, таких как apt, dpkg, rsyslog и так далее.


По умолчанию logrotate.conf настраивает еженедельную ротацию, при этом логи принадлежат пользователю root и группе syslog. Одновременно сохраняются четыре файла (rotate 4), а новые пустые логи создаются после ротации текущего лога (create).     

__Основные параметры конфигов logrotate__     

Частота проверки по условиям:
- hourly - каждый час
- daily - каждый день
- weekly - каждую неделю
- monthly - каждый месяц
- yearly - каждый год

__logrotate: условия__    
- rotate — указывает, сколько старых логов нужно хранить (в параметрах передаетсяколичество);
- create — создание пустого файла лога после перемещения старого;
- dateext — перед заголовком старого лога добавляется дата ротации;
- compress — сжатие логов;
- delaycompress — не сжимать последний и предпоследний журнал;
- extension — сохранять оригинальный лог-файл после ротации, если у него указанорасширение;
- mail — отправлять e-mail после завершения ротации;
- maxage — выполнять ротацию журналов, если они старше, чем указано;
- missingok — не выдавать ошибки, если лог-файла не существует;
- olddir — перемещать старые логи в отдельную папку;
- start — номер, с которого будет начинаться нумерация старых логов;
- size — размер лога, когда он будет перемещен.
- notifempty – не ротировать файл лога, если он пуст.
- copytruncate – обрезать оригинальный файл до нулевого размера после создания копии вместо переименования оригинального файла и создания нового
- postrotate/prerotate -> endscript – cтроки, находящиеся между данными служебными словами, каждое из которых должно находиться в отдельной строке, выполняются с использованием /bin/sh после ротации файла журнала. Параметр sharedscripts означает, что скрипт postrotate будет выполнятся только один раз, а не после обработки каждого файла.


__logrotate: пример конфигурации__    
```
[root@logs ~]# cat /etc/logrotate.d/nginx
/var/log/nginx/*.log {
daily
missingok
rotate 52
compress
delaycompress
notifempty
create 0640 www-data adm
sharedscripts
prerotate
if [ -d /etc/logrotate.d/httpd-prerotate ]; then \
run-parts /etc/logrotate.d/httpd-prerotate; \
fi \
endscript
```
Проверка конкретного конфига logrotate без применения:
```
logrotate -d /etc/logrotate.d/chrony
```
Применение конкретного конфига logrotate с выводом сообщений в консоль:
```
logrotate -v /etc/logrotate.d/auth
```
Запуск всех конфигов logrotate:
```
logrotate -v /etc/logrotate.conf
```

  ### Journald
journald - система регистрации событий в systemd    

__Особенности:__
- бинарный формат логов (защита от подделки, возможность конвертации в другие форматы)
- не требует специальной настройки
- структурированные данные (multi-field, multi-line)
- индексированные данные
- центральное хранилище логов


__Какие логи принимает journald?__     
- простые syslog логи логи ядра (kmsg)
- структурированные данные через Journal API
- логи и статусы systemd юнитов записи системы аудита (auditd)

__/etc/systemd/journald.conf__ - конфигурационный файл journald

__journald: параметры конфигурации__
- Storage (volatile, persistent, auto, none) - по-умолчанию auto (пишет логи в tmpfs), чтобы писать логи на диск - нужно поставить persistent
- Compress (yes, no) - сжимает данные перед записью
- Seal (yes, no) - накладывает криптографическую печать
- ForwardToSyslog, ForwardToKMsg, ForwardToConsole, ForwardToWall - опции перенаправления сообщений
- MaxLevelStore, MaxLevelSyslog, MaxLevelKMsg, MaxLevelConsole, MaxLevelWall - задаем уровни важности сообщений для разных логов
- SystemMaxUse - максимальный объем, который логи могут занимать на диске
- SystemKeepFree - объем свободного места на диске, после сохранения логов
- SystemMaxFileSize - объем файла лога, по достижении которого он должен быть удален с диска
- RuntimeMaxUse - максимальный объем, который логи могут занимать в файловой системе /run
- RuntimeKeepFree - объем свободного места на /run, после сохранения логов
- RuntimeMaxFileSize - объем файла лога, по достижении которого он должен быть удален из файловой системы/run

__Работа с журналом__    

__journalctl -b__ - покажет сообщения с ммоента загрузки системы 
__journalctl -p err -b__ - посмотреть только ошибки с момента последней загрузки        
__journalctl -e__  - покажет журнал с конца    
__journalctl -xe__ - покажет журнал с конца с расширенными событиями    
__journalctl -xe -o json-pretty__ - Вывод сообщений в структурированном json           
__journalctl -b | grep__  фильтруем по слову     
__journalctl --since "2024-10-15 00:00:00"__ - фильтруем по дате    
__journalctl --since "2024-10-15 00:00:00" --until "2024-10-15 08:00:00"__ - фильтруем от и до    
__journalctl - xeu nginx.service__ - посмотреть логи относящиеся к конкретному сервису   
__journactl -u mysqld.service -f__ - Вывод сообщений по заданному systemd юниту в формате чтения из файла    
__journalctl__ _UID=1001 -  Вывод сообщений процессов, запущенных от имени пользователя с заданным UID    
__journalctl -n 3 -p crit__ -   Вывод последних трех сообщений с уровнем важности crit    


__journalctl --flush__ - Перенести все логи из /run в /var   
__journalctl --vacuum-size=1G__ - Задать максимальный размер хранящихся логов    
__journalctl --vacuum-time=1years__ - Задать максимальное время хранения логов   
__journalctl --disk-usage__ - Показать занимаемый логами объем диска     

__journald: централизованное хранение__    

<p align="center">
<image src="https://github.com/LLlMEJIb87/LINUX/blob/main/%D0%9B%D0%BE%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/Picture/journal_d.PNG">
</p>  

- systemd-journal-remote - демон для приема и сбора логов с удаленных хостов (работает в активном или пассивном режиме)
- systemd-journal-gatewayd - http-сервер для приема логов на центральный хост по протоколу http
- systemd-journal-upload - демон для загрузки логов с локальной машины в удаленное хранилище
### Auditd

<p align="center">
<image src="https://github.com/LLlMEJIb87/LINUX/blob/main/%D0%9B%D0%BE%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/Picture/audit_d.PNG">
</p>

__auditd__ - подсистема аудита в ядре Linux, отслеживает критичные с точки зрения безопасности системные события    

В подсистему аудита входят демон auditd и несколько вспомогательных утилит:
- auditctl — утилита для управления демоном auditd; позволяет получать информацию о текущем состоянии подсистемы аудита, а также добавлять и удалять правила;
- autrace — утилита для аудита событий, порождаемых процессами (работает по тому же принципу, что и strace);
- ausearch — утилита для поиска событий в журнальных файлах;
- aureport — утилита для генерации отчётов о работе системы аудита.    


__auditd:__
- Пишет логи аудита
- Для удобства просмотра логов можно использовать ausearch и aureport
- Команда auditctl позволяет настраивать правила аудита вручную
- После загрузки системы правила читаются из /etc/audit/audit.rules
- Некоторые параметры auditd можно изменить в /etc/audit/auditd.conf


__Конфигурирование auditd__    
Настройки подсистемы аудита хранятся в конфигурационном файле /etc/audit/auditd.conf. Он содержит в числе прочих следующие параметры:
- log_file — файл, в котором будут храниться логи подсистемы аудита;
- log_format — формат, в котором будет сохранены логи;
- freq — максимальное число записей протокола, которые могут храниться в буфере;
- flush — режим синхронизации буфера с диском (none — ничего не делать, incremental — переносить данные из буфера на диск с частотой, указанной в значении параметра freq; data — синхронизировать немедленно, sync —
синхронизировать как данные, так и метаданные файла при записи на диск);
- max_log_file — максимальный размер файла лога в мегабайтах;
- max_log_file_action — действие при превышении максимального размера файла лога;
- space_left — минимум свободного пространства в мегабайтах, по достижении которого должно быть осуществлено действие, указанное в следующем параметре;
- space_left_admin — указывает, что делать, когда на диске недостаточно свободного места (ignore — ничего не делать; syslog — отправлять в syslog, email — отправлять уведомление по почте;
- suspend — прекратить запись логов на диск;
- single — перейти в однопользовательский режим; halt — выключить машину)
- disk_full_action — действие, которое нужно осуществить при переполнении диска (этот параметр может принимать те же значения, что и space_left_admin)


__Создание правил auditd__     
```
auditctl -a <список>, <действие> -S <имя системного вызова> -F <фильтры>
```  
После опции -а указывается список, в который нужно добавить правило. Всего существует 5 таких списков:
- task — события, связанные с созданием новых процессов;
- entry — события, которые имеют место при входе в системный вызов;
- __exit — события, которые имеют место при выходе из системного вызова;__
- user — события, использующие параметры пользовательского пространства;
- exclude — используется для исключения событий.

Затем указывается, что нужно делать после наступления события. Здесь возможны два варианта: always (события будут записываться в журнал) и never (не будут).    
После опции -S идёт имя системного вызова, при котором событие нужно перехватить (open, close и т.п.).     
После опции -F указываются дополнительные параметры фильтрации.     
Если нам требуется вести аудит обращений к файлам из каталога /etc, правило будет выглядеть так:
```
sudo auditctl -a exit,always -S open -F path=/etc
```

Рассмотрим пример типового файла правил:
```
# отслеживать системные вызовы unlink () и rmdir()
-a exit,always -S unlink -S rmdir
# отслеживать системные вызовы open () от пользователя с UID 1001
-a exit,always -S open -F loginuid=1001
# отслеживать доступ к файлам паролей и групп и попытки их изменения:
-w /etc/group -p wa
-w /etc/passwd -p wa
-w /etc/shadow -p wa
-w /etc/sudoers -p wa
# отслеживать доступ к следующей директории:
-w /etc/my_directory -p r
```
### dmesg
Команда dmesg показывает кольцевой буфер сообщений ядра — это логи, которые записывает ядро Linux о загрузке системы, обнаружении оборудования, подключении устройств, драйверах и других системных событиях.
```
dmesg -T
```

## Централизованный сбор логов с помощью ELK
__Компоненты__
- **E**lasticsearch — база данных для надёжного хранения документов
- **L**ogstash — обработка данных из логов
- **K**ibana — визуализация данных из Elasticsearch (дашборды)
- Beats — агенты сбора данных для сохранения в ELK-стеке   
  Компоненты могут быть требовательными к оперативной памяти, полный стек — 4 GB минимум

  __Beats__
- Filebeat — основной поставщик данных в ELK
- Heartbeat — проверка сервисов
- Auditbeat — события auditd (безопасность)
- Metricbeat — метрики для мониторинга системы

 <p align="center">
<image src="https://github.com/LLlMEJIb87/LINUX/blob/main/%D0%9B%D0%BE%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/Picture/ELK_dvij.PNG">
</p>    

Beats - собирают логи и отправляют   
Logstah - обработка/преобразование логов
Elasticsearch - хранение логов
kibana - визуализация   

### Cеть
 <p align="center">
<image src="https://github.com/LLlMEJIb87/LINUX/blob/main/%D0%9B%D0%BE%D0%B3%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5/Picture/ELK_network.PNG">
</p>    

## Установка и настройка
### Elasticsearch - база данных
1. Устанавливаем зависимости, так как elasticsearch работает на java
```
sudo apt install default-jdk -y
```
2. Устанавливаем пакет с elasticsearch
```
sudo dpkg -i elasticsearch-8.9.1-amd64.deb
```
3. Прописываем лимит оперативной памяти для java
```
root@elk:/etc/elasticsearch/jvm.options.d# cat > jvn.options
-Xms1g
-Xmx1g
```
4. Настраиваем конфиг elasticsearch в упрощенном режиме
```
nano /etc/elasticsearch/elasticsearch.yml
xpack.security.enabled: false - выключаем
xpack.security.http.ssl:
  enabled: false - выключаем
xpack.security.transport.ssl:
  enabled: false - выключаем

http.host: 0.0.0.0 - если устанволены все нули, то сможем зайти по ip машины
```
5. Стартуем elasticsearch
```
systemctl daemon-reload  - обновляем описание сервисов
systemctl enable --now elasticsearch.service - ставим в автозагрузку и автоматически стартуем
```
6. Elasticsearch слушает 9200 порт, проверить можно следующим образом
```
curl http://localhost:9200
```
### Kibana - визуализация
1. Устанавливаем пакет
```
dpkg -i kibana-8.9.1-amd64.deb
```
2. Меняем настройки
```
nano /etc/kibana/kibana.yml
server.port: 5601 - раскоментировали
erver.host: "0.0.0.0" установили нули, для возможности заходить на него по ip машины
```
3. Стартуем сервис
```
systemctl daemon-reload  - обновляем описание сервисов
systemctl enable --now kibana.service - ставим в автозагрузку и автоматически стартуем
```
4. Kibana слушает 5601 порт
### logstash - обработка логов, посредник который принимает файлы с beats и отправляет в elasticsearch
1. Устанавливаем сервис
```
dpkg -i logstash-8.9.1-amd64.deb
```
2. Меняем настройки
```
nano /etc/logstash/logstash.yml
path.config: /etc/logstash/conf.d указываем путь
```
3. Стартуем сервис
```
systemctl daemon-reload  - обновляем описание сервисов
systemctl enable --now logstash.service - ставим в автозагрузку и автоматически стартуем
```
4. Делаем настройки, которые будут преобразовывать файлы logstash для NGINX
```
cat > /etc/logstash/conf.d/logstash-nginx-es.conf - создаем файл
input {                #input - откуда он получает данные
    beats {
        port => 5400
    }
}

filter {               #filter - что он делает с этими данными
 grok {
   match => [ "message" , "%{COMBINEDAPACHELOG}+%{GREEDYDATA:extra_fields}"]
   overwrite => [ "message" ]
 }
 mutate {
   convert => ["response", "integer"]
   convert => ["bytes", "integer"]
   convert => ["responsetime", "float"]
 }
 date {
   match => [ "timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ]
   remove_field => [ "timestamp" ]
 }
 useragent {
   source => "agent"
 }
}

output {             #output - куда мы отправляем данные
 elasticsearch {
   hosts => ["http://localhost:9200"]
   #cacert => '/etc/logstash/certs/http_ca.crt'
   #ssl => true
   index => "weblogs-%{+YYYY.MM.dd}"
   document_type => "nginx_logs"
 }
 stdout { codec => rubydebug }
}
```
### filebeat агент сбора логов
1. Устанавливаем сервис
```
dpkg -i filebeat-8.9.1-amd64.deb
```
2. Настраиваем
```
nano /etc/filebeat/filebeat.yml
после этой строки добавляем запись ниже  #- c:\programdata\elasticsearch\logs\* 
filebeat.inputs:
- type: filestream
  paths:
    - /var/log/nginx/*.log

Коментим эти строки:
#output.elasticsearch:
# hosts: ["localhost:9200"]
Раскоментируем следующие строки:
output.logstash:
hosts: ["localhost:5400"] - меняем порт на 5400
```
3. запускаем сервис
```
systemctl daemon-reload  - обновляем описание сервисов
systemctl enable --now filebeat.service - ставим в автозагрузку и автоматически стартуем
```
4. filebeat слушает порт 5400 - который мы прописали в конфиге

## Проверка и просмотр
1. Можем тестов нагенерить логов, обращася к curl localhost
2. Идем в **kibana** через web на ip машины порт 5061
3. Выбираем Explore on my own
4. discover -> create data view
5. собираем index (это как таблица в базе данных с который мы будем получать данные) -> Name Nginx -> Index Pattern weblogs* -> Timestap @timestamp -> save data view

__Делаем визуализацию__
1. Вкаладка dashboard -> create dashboard
2. Create vizualization     
...    
3. Save - сохранить проект   



